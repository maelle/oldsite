---
layout: post
title: "Names of b.....s badder than Taylor Swift"
comments: true
---
```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE,
                      message = FALSE,
                      warning = FALSE, 
                      cache = TRUE) 
```

Again, a Twitter trend sent me to my R prompt... Here is a [bit of context](http://junkee.com/taylor-swift-badder-bitch/137625). My summary: Taylor Swift apparently plays the bad girl in her new album and a fan of hers asked a question...

<blockquote class="twitter-tweet" data-lang="ca"><p lang="en" dir="ltr">Name a bitch badder than Taylor Swift üòçüòõüò§ <a href="https://t.co/AkSyQBUIME">pic.twitter.com/AkSyQBUIME</a></p>&mdash; Nutella (@xnulz) <a href="https://twitter.com/xnulz/status/928857792982781952?ref_src=twsrc%5Etfw">10 de novembre de 2017</a></blockquote>


The tweet was then quoted by many people mentioning badass women, and I decided to have a look at these heroes!

<!--more-->

# Name tweets badder than Nutella's

I was a bit lazy and asked Mike Kearney, `rtweet` maintainer, how to find tweets quoting a tweet, to which [Bob Rudis answered](https://twitter.com/hrbrmstr/status/937340032456814592). Now that I even had the code, it was no trouble at all getting the data. I added the filtering steps myself, see, I'm not _that_ lazy. I also removed the link to the quoted tweet that was at the end of each tweet. 

```r
question_tweet <- "928857792982781952"
badass <-  rtweet::search_tweets(question_tweet, n = 18000, include_rts = FALSE)
badass <- dplyr::filter(badass, is_quote_status, quote_status_id == question_tweet)
badass <- dplyr::mutate(badass, text = stringr::str_replace(text, "https://t\\.co/.*$", ""))
badass <- dplyr::mutate(badass, text = trimws(text))
readr::write_csv(badass, path = "data/2017-12-03-badderb_badass.csv")
```

```{r, echo = FALSE}
badass<- readr::read_csv("data/2017-12-03-badderb_badass.csv")
```

I obtained `r nrow(badass)` tweets. Not bad!

```{r}
library("magrittr")
set.seed(20171015)
indices <- sample.int(n = 15)
badass$text[indices]

```


# Names of the badder b.....s

Quite a few of the tweets from this trend contained the name of someones. In order to extract these names, I resorted to a language processing method called entity extraction, the entity here being a person. For that, I could have used an [extractor module](https://app.monkeylearn.com/main/extractors/ex_isnnZRbS/) of the Monkeylearn platform [via my own `monkeylearn` package](https://github.com/ropensci/monkeylearn).

Instead, I chose to illustrate a different method: using the [`clean`]`NLP` package{(https://github.com/statsmaths/cleanNLP) that I know from [the excellent R Journal paper presenting it](https://journal.r-project.org/archive/2017/RJ-2017-035/RJ-2017-035.pdf). Among other things, it serves as an interface between R and the [Python library spaCy](https://spacy.io/) and also as an interface between R and [the coreNLP Java library](https://stanfordnlp.github.io/CoreNLP/). Installing these tools is the painful part of the setup, but 1) you only need to install one of them 2) there are detailed instructions [here](https://github.com/statsmaths/cleanNLP#backends) 3) once your tool is installed, using the package is a breeze (and well independent of any rate limit contrary to `monkeylearn` use). I am at that breeze stage, you can be jealous. 
 
There were a few tweets with infuriating encoding issues, BOM or something like that, and I decided to just ignore them by using `purrr::possibly`. I obviously did this to illustrate the use of this `purrr` function, not out of laziness.
 
```r
library("cleanNLP")
init_spaCy()
# we need to remove characters like "\u0098"
badass <- dplyr::mutate(badass, text = enc2native(text))

get_entities_with_text <- function(x){
  obj <- run_annotators(x, as_strings = TRUE)
  entities <- get_entity(obj)
  entities$text <- x
  entities
}

possibly_get_entities <- purrr::possibly(get_entities_with_text,
                                         otherwise = NULL)

entities <- purrr::map_df(badass$text, possibly_get_entities)

readr::write_csv(entities, path = "data/2017-12-03-badderb_entities.csv")

```

```{r, echo = FALSE}
entities <- readr::read_csv("data/2017-12-03-badderb_entities.csv")
```

I got at least one entity for `r length(unique(entities$text))` out of `r nrow(badass)` tweets, and at least one _person_ for `r length(unique(entities[entities$entity_type == "PERSON",]$text))`. I am very satisfied with this.


# So, who are you, badder b.....s?

We get this kind of entities: `r unique(entities$entity_type)`. I'm more interested in PERSONand no, I'm not shouting. I chose to look at the top 12 in order to get a top 10 excluding Taylor Swift herself.

```{r}
entities %>%
  dplyr::filter(entity_type == "PERSON") %>%
  dplyr::group_by(entity) %>%
  dplyr::summarise(n = n()) %>%
  dplyr::arrange(- n) %>%
  head(n = 12) %>%
  knitr::kable()

```

At that point I did feel like bursting out laughing though. Dora! And I checked, we're talking about Dora the explorer! Joan is Joan of arc. Interestingly in that top 10 we're mixing really bad persons, e.g. Myra Hindley was a serial killer, and really badass persons, like Rosa Parks. My husband will be happy to see Marie Curie in this list, since he's a big fan of hers, having even guided a few tours about her life in Paris.

Looking at the most frequently mentioned women obviously makes us loose well wrongly written names, and most importantly personal stories of badass mothers and the like, and of native women for instance, although I have the impression of having read about a few but probably because of my following [Auriel Fournier](https://twitter.com/RallidaeRule).

# Writing history?

I saw someone said they'd use the tweets as basis for history lessons. In order to get a view of a person, one could concatenate the tweets about them. Take Marie Curie for instance.

```{r}
entities %>%
  dplyr::filter(entity_type == "PERSON", entity == "Marie Curie") %>%
  dplyr::summarise(text = toString(text)) %>%
  .$text
```

Doing this one also gets the name of many other women. Moreover, if writing history lessons, one should have several sources, right? What about Wikidata [like in this other blog post of mine](http://www.masalmon.eu/2017/08/06/p1/)?

```{r}
# function for getting someone's data
get_someone_data <- function(name, pb = NULL){
  if (!is.null(pb)) pb$tick()$print()
  Sys.sleep(1)
  item <- WikidataR::find_item(name, language = "sv")
  # sometimes people have no Wikidata entry so I need this condition
  if(length(item) > 0){
    entity_code <- item[[1]]$id
    query <-  paste0("PREFIX entity: <http://www.wikidata.org/entity/>
                     #partial results
                     
                     SELECT ?propUrl ?propLabel ?valUrl ?valLabel ?picture
                     WHERE
                     {
                     hint:Query hint:optimizer 'None' .
                     {	BIND(entity:",entity_code," AS ?valUrl) .
                     BIND(\"N/A\" AS ?propUrl ) .
                     BIND(\"identity\"@sv AS ?propLabel ) .
                     }
                     UNION
                     {	entity:", entity_code," ?propUrl ?valUrl .
                     ?property ?ref ?propUrl .
                     ?property rdf:type wikibase:Property .
                     ?property rdfs:label ?propLabel
                     }
                     
                     ?valUrl rdfs:label ?valLabel
                     FILTER (LANG(?valLabel) = 'sv') .
                     OPTIONAL{ ?valUrl wdt:P18 ?picture .}
                     FILTER (lang(?propLabel) = 'sv' )
                     }
                     ORDER BY ?propUrl ?valUrl
                     LIMIT 200")
    results <- WikidataQueryServiceR::query_wikidata(query)
    results$name<- name
    results
  }else{
    NULL
  }
   
  }

pb <- dplyr::progress_estimated(length(unique(sommargaester$name)))
sommargaester_wiki <- purrr::map_df(unique(sommargaester$name),
                                    get_someone_data, pb=pb)

sommargaester <- dplyr::left_join(sommargaester, sommargaester_wiki, by = "name")

readr::write_csv(sommargaester, path = "data/p1_wiki_data.csv")

```